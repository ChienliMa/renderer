"""
Systhetic data generator

@Author: Chienli Ma
@date: 2015.01.08

Incentive:

Reference:

Dependencies:
    numpy, scipy, PIL, pygame, cv2(opencv)
    Blends: https://github.com/ChienliMa/Blends
    Distortions: https://github.com/ChienliMa/Distortions
"""

import os
import numpy as np
from numpy.random import randint, uniform
from scipy import misc
import cv2
import pygame
from PIL import Image, ImageFont, ImageDraw
from distortions import distort
from blends import random_blend 

# useful color tuples
white = ( 255, 255, 255 )
black = ( 0, 0, 0)

# border mode
no_border = 0
shadow_border = 1
border_border = 2

def render( text, font_file, color, bg, font_size ):
    """
    Render text on random background image to mimic real scene images.

    Parameters:
        text - String of test you want to render.
        font_file - Path to corresponding truetype font file. 
                    i.e. \'./fonts/font.ttf\'
        color - List of tuples. Each tuple represents a base color which is\
                generated by clustering natural scene text image.
        bg - 3 dimension numpy.ndarray. Backgoud image used blends with base \ 
                color images, providing natural texture.
        font_size - Integer. Font size.

    Returns:
        A unresized 3 dimension numpy.ndarray. 
    """
    # get base color of 3 layer
    try:
        b_color, f_color, s_color = color
    except:
        b_color, f_color = color
        s_color = b_color

    f_color = tuple(f_color)
    s_color = tuple(s_color)
    b_color = tuple(b_color)

    # random pad width, pad text with p_w
    p_w = randint( 0, 5 )
    # real size of the text have a range
    font = pygame.font.Font( font_file , randint( font_size/2, font_size * 2 ))
    img_h, img_w = font.size( text )
    img_h += p_w * 2
    img_w += p_w * 2
    img_size = ( img_w ,img_h  )

    # generate base color of each layers, and then blends with random 
    # backgroud image, providing different textures.
    f_base = np.tile( [[f_color]], [img_h,img_w,1] )
    b_base = np.tile( [[b_color]], [img_h,img_w,1] )

    # half of the text img have complex background
    if uniform( 0, 1) < 0.7:
        b_back = random_crop( bg, img_size )
        top_alpha = np.tile( [[[ uniform(0.5,0.8) ]]], [img_h,img_w,3] )
        base_alpha = np.tile( [[[ uniform(0.2,0.5) ]]], [img_h,img_w,3] )
        b_base = random_blend( b_base, b_back, top_alpha, base_alpha )

    # uncomment following line to blend foreground with random background
    # this will provide text with complex texture
    # if uniform( 0, 1 ) < 0.5:
    #     f_back = random_crop( bg, img_size )
    #     top_alpha = np.tile( [[[uniform(0.5,0.8)]]], [img_h,img_w,3] )
    #     base_alpha = np.tile( [[[uniform(0.2,0.5)]]], [img_h,img_w,3] )
    #     f_base = random_blend( f_base, f_back, top_alpha, base_alpha )

    # render foreground mask( Aplha channel )
    surface = font.render(text, True, white, black )    
    f_mask =np.array( pygame.surfarray.array2d( surface ) ) 
    
    # whether text have border, shadow or nothing:
    # 0 for no middle later, 1 for shadow, 2 for border 
    border_mode = randint( 0, 3 )
    if border_mode != no_border:
        # second(middle) layer share the save background as background layer
        s_base = np.tile( [[s_color]], [img_h,img_w,1] )
        s_base = random_blend( s_base, b_base )

        
        if border_mode == border_border:    
            width = randint(0,0.1*font_size+1)*2 + 1
            # dilate with odd width to generate border
            s_mask = cv2.dilate( f_mask, np.ones([width,width]) )
        elif border_mode == shadow_border:  
            # motion blur generates shadow effect
            s_mask = distort( f_mask, 'blur', 0.7 )

    # combine 3 layer to get final result
    result = b_base
    
    # comment folloing line to avoid adding perspective transform 
    # to second layer and forground layer 
    perspective_mat = get_random_perspective( result.shape )
    if border_mode:
        s_mask =cv2.warpPerspective( s_mask, perspective_mat, img_size )
        s_mask = np.where( s_mask!=0 )
        result[ s_mask ] = s_base[ s_mask]
    f_mask =cv2.warpPerspective( f_mask, perspective_mat, img_size )        
    
    # add second layer to background layer; cover them with foreground layer
    f_mask_m = np.where( f_mask!=0 )
    result[ f_mask_m ] = f_base[ f_mask_m ]

    # add gaussian noise pollution and motion blur
    if uniform(0,1) < 0.5 :
        result = distort( result, 'gaussian_noise', 0.2 )
    result = distort( result, 'blur', 0.9 )

    # crop text, this will 
    result = crop_result( result, f_mask )
    result = result.swapaxes(0,1)    

    # add distortion to result image, you can add various distrotion below
    if uniform(0,1) < 0.9:
        result = distort( result, 'slant', 0.5 ) 

    return result 

def crop_result( src, f_mask ):
    """
    """
    h, w, c = src.shape 
    row, col = np.where( f_mask != 0 )

    top = row[0]
    buttom = row[-1]
    left = col.min()
    right = col.max()

    top = max( top - randint( 1, h/8 + 1 ), 0 )
    buttom = min( buttom + randint( 1, h/8 + 1 ), h - 1 )
    left = max( left - randint( h/4, h/2 + 1), 0 )
    right = min( right + randint( h/4, h/2 + 1 ), w - 1)

    return src[top:buttom, left:right,:]

def random_crop( src, crop_size ):
    """
    Corp image with size of crop_size.

    Parameters:
        src - 3 dimension numpy.ndarray. The background image.
        crop_size - Tuple. ( widht, height )? 
                    I am not sure cause there are 2 kinds of coordiantes.
    Returns:
        Image randomly cropped from src.
    """
    src = src.swapaxes(0,1)
    w, h, c = src.shape
    if w <= crop_size[1] or h < crop_size[0]:
        return cv2.resize( src, crop_size )
    else:
        b_x = randint( 0, w - crop_size[1] - 1 )
        b_y = randint( 0, h - crop_size[0] - 1 )
        return src[ b_x:b_x+crop_size[1], b_y:b_y+crop_size[0], : ] 

def get_random_affine( shape, complex = 0.7):
    """
    Generate random affine transformation matrix

    Parameters:
        shape - Shape of images gained by numpy.ndarray.shape
        complex - Comlexity of the transformation which defines the transform \
                    angle range and scale range.

    Returns:
        2x3 affine transform mat
    """
    theta = uniform( -20*complex,20*complex )
    scale = uniform( 1-0.5*complex, 1+0.5*complex)
    center = ( shape[0]//2 , shape[1]//2 )
    return cv2.getRotationMatrix2D( center, theta, scale )

def get_random_perspective( shape, range = 0.0625 ):
    """
    Generate a random perspective transformation matrix.

    Parameters:
        shape - Shape of images gained by numpy.ndarray.shape
        range - The range of shifts of 4 corners. Should be smaller than 0.5

    Returns:
        3x3 perspective transform matrix
    """
    assert range < 0.5
    h, w, c = shape
    h -= 1
    w -= 1

    top_left = [0, 0]
    top_right = [0, h - 1]
    buttom_left = [w - 1, 0]
    buttom_right = [w - 1, h - 1]
    src = np.array([ top_left, top_right, buttom_left, buttom_right ], \
            dtype = 'float32')

    top_left = [ randint( 0, range*w + 1), randint( 0, range*h + 1 ) ]
    top_right = [ randint( 0, range*w + 1), randint( (1-range)*h, h + 1 ) ]
    buttom_left = [ randint( ( 1-range)*w, w + 1), randint( 0, range*h + 1 ) ]
    buttom_right = [ randint( (1-range)*w, w + 1), randint( (1-range)*h, h + 1 ) ]
    dst =  np.array([ top_left, top_right, buttom_left, buttom_right ],
                    dtype = 'float32')
    return cv2.getPerspectiveTransform( src, dst)







